{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "61f6e27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import ast\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "from api_ocr import call_mistral_ocr\n",
    "from local_ocr import call_local_ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fccb8ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------\n",
    "# STEP 1: Read config.txt and api_key.txt\n",
    "# -------------------\n",
    "def read_config(config_path=\"config.txt\"):\n",
    "    config = {}\n",
    "    with open(config_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            if \"=\" in line:\n",
    "                key, value = line.strip().split(\"=\", 1)\n",
    "                config[key.strip()] = value.strip()\n",
    "    return config\n",
    "\n",
    "config = read_config()\n",
    "\n",
    "variant = config.get(\"variant\")\n",
    "input_image_size = tuple(map(int, config.get(\"input_image_size\").split(\"x\")))\n",
    "image_dir = config.get(\"image_dir\", \"input\")\n",
    "output_dir = config.get(\"output_dir\", \"output\")\n",
    "config_lang = config.get(\"language\", \"\").lower()  # NEW\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Check for API key\n",
    "api_key_path = \"api_key.txt\"\n",
    "\n",
    "try:\n",
    "    with open(api_key_path, \"r\") as f:\n",
    "        api_key = f.read().strip()\n",
    "except FileNotFoundError:\n",
    "    print(\"API key file not found. Using local model...\")\n",
    "    api_key = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "168939b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------\n",
    "# STEP 2: Load var_ref.py to get Gamma document\n",
    "# -------------------\n",
    "def load_var_ref(file_path=\"var_ref.py\"):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        content = f.read()\n",
    "    var_ref = ast.literal_eval(content.split(\"=\", 1)[1].strip())\n",
    "    return var_ref\n",
    "\n",
    "var_ref = load_var_ref()\n",
    "gamma_file = var_ref.get(variant)\n",
    "gamma_path = os.path.join(\"gamma-master\", gamma_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b189c4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------\n",
    "# STEP 3: Load Gamma CSV\n",
    "# -------------------\n",
    "df = pd.read_csv(gamma_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ff225aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------\n",
    "# STEP 4: Check image size tolerance\n",
    "# -------------------\n",
    "def check_image_size(image_path, expected_size, tolerance=0.02):\n",
    "    img = Image.open(image_path)\n",
    "    actual_size = img.size  # (width, height)\n",
    "    return all(abs(a - e) / e <= tolerance for a, e in zip(actual_size, expected_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "392c3041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------\n",
    "# STEP 5: Extract buic id & language from filename\n",
    "# -------------------\n",
    "def parse_filename(filename):\n",
    "    match = re.match(r\".*_(\\d+_\\d+)_([A-Z]+)\\.png\", filename, re.IGNORECASE)\n",
    "    if match:\n",
    "        buic_id = match.group(1)\n",
    "        lang = match.group(2).lower()\n",
    "        return buic_id, lang\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "150d5051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------\n",
    "# STEP 6: Process images\n",
    "# -------------------\n",
    "results = []\n",
    "mismatch_counter = {}  # track mismatches per language\n",
    "\n",
    "for filename in os.listdir(image_dir):\n",
    "    if not filename.lower().endswith(\".png\"):\n",
    "        continue\n",
    "\n",
    "    image_path = os.path.join(image_dir, filename)\n",
    "\n",
    "    # Extract buic id and language (if not in config)\n",
    "    buic_id, lang = parse_filename(filename)\n",
    "    if not buic_id:\n",
    "        continue\n",
    "\n",
    "    # Row lookup\n",
    "    row = df[df[df.columns[0]] == buic_id]\n",
    "    if row.empty:\n",
    "        continue\n",
    "\n",
    "    # Determine language columns\n",
    "    if config_lang and config_lang != \"all\":\n",
    "        lang_cols = [c for c in df.columns if c.startswith(config_lang)]\n",
    "    elif config_lang == \"all\":\n",
    "        lang_cols = [c for c in df.columns if re.match(r\"^[a-z]{2}\", c, re.I)]\n",
    "    else:\n",
    "        # fallback: infer from filename\n",
    "        if not lang:\n",
    "            continue\n",
    "        lang_cols = [c for c in df.columns if c.startswith(lang)]\n",
    "\n",
    "    if not lang_cols:\n",
    "        continue\n",
    "\n",
    "    # Combine expected texts for each language prefix\n",
    "    grouped_langs = {}\n",
    "    for col in lang_cols:\n",
    "        prefix = re.match(r\"^[a-z]+\", col, re.I).group(0).lower()\n",
    "        val = str(row.iloc[0][col]) if not pd.isna(row.iloc[0][col]) else \"\"\n",
    "        val = val.strip()\n",
    "        if not val:\n",
    "            continue\n",
    "        if prefix not in grouped_langs:\n",
    "            grouped_langs[prefix] = []\n",
    "        grouped_langs[prefix].append(val)\n",
    "\n",
    "    if not grouped_langs:\n",
    "        continue\n",
    "\n",
    "    # Initialize row\n",
    "    row_result = {\"Id\": buic_id}\n",
    "\n",
    "    # Handle size mismatch\n",
    "    if not check_image_size(image_path, input_image_size):\n",
    "        for prefix, expected_list in grouped_langs.items():\n",
    "            combined_expected = \" \".join(expected_list)\n",
    "            row_result.update({\n",
    "                f\"{prefix} Expected\": combined_expected,\n",
    "                f\"{prefix} Extracted\": \"Faulty image\",\n",
    "                f\"{prefix} Result\": \"FAIL\"\n",
    "            })\n",
    "            mismatch_counter[prefix] = mismatch_counter.get(prefix, 0) + 1\n",
    "        results.append(row_result)\n",
    "        continue\n",
    "\n",
    "    # OCR Handling\n",
    "    if api_key:  # Use Mistral OCR API\n",
    "        ocr_response = call_mistral_ocr(api_key, image_path)\n",
    "    else:  # Use local OCR\n",
    "        ocr_response = call_local_ocr(image_path)\n",
    "\n",
    "    pages = ocr_response.get(\"pages\", [])\n",
    "    if pages:\n",
    "        text = \" \".join(page.get(\"markdown\", \"\") for page in pages)\n",
    "        extracted_text = \" \".join(text.split()).strip()\n",
    "    else:\n",
    "        extracted_text = \"\"\n",
    "\n",
    "    # For each language (combine columns)\n",
    "    row_result = {\"Id\": buic_id}\n",
    "    for prefix, expected_list in grouped_langs.items():\n",
    "        if any(e in [\"{#1}\", \"(#1)\"] for e in expected_list):\n",
    "            row_result.update({\n",
    "                f\"{prefix} Expected\": \" \".join(expected_list),\n",
    "                f\"{prefix} Extracted\": \"dynamic input\",\n",
    "                f\"{prefix} Result\": \"SKIP\"\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        combined_expected = \" \".join(expected_list)\n",
    "        result = \"PASS\" if combined_expected in extracted_text else \"FAIL\"\n",
    "        if result == \"FAIL\":\n",
    "            mismatch_counter[prefix] = mismatch_counter.get(prefix, 0) + 1\n",
    "\n",
    "        row_result.update({\n",
    "            f\"{prefix} Expected\": combined_expected,\n",
    "            f\"{prefix} Extracted\": extracted_text,\n",
    "            f\"{prefix} Result\": result\n",
    "        })\n",
    "\n",
    "    results.append(row_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5d28a197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to output\\C1AHSEVO_AMDC_ocr_results (1).csv\n"
     ]
    }
   ],
   "source": [
    "# -------------------\n",
    "# STEP 7: Save results CSV\n",
    "# -------------------\n",
    "if results:\n",
    "    # Collect all headers (preserve order: Id first, then langs)\n",
    "    fieldnames = [\"Id\"]\n",
    "    for r in results:\n",
    "        for key in r.keys():\n",
    "            if key not in fieldnames:\n",
    "                fieldnames.append(key)\n",
    "\n",
    "    # Base filename\n",
    "    base_file = os.path.join(output_dir, f\"{variant}_ocr_results.csv\")\n",
    "    output_file = base_file\n",
    "\n",
    "    # If file exists, add suffix (1), (2), ...\n",
    "    if os.path.exists(output_file):\n",
    "        counter = 1\n",
    "        base_name, ext = os.path.splitext(base_file)\n",
    "        while os.path.exists(output_file):\n",
    "            output_file = f\"{base_name} ({counter}){ext}\"\n",
    "            counter += 1\n",
    "\n",
    "    # Write CSV\n",
    "    with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(results)\n",
    "\n",
    "        # Write mismatch counts row\n",
    "        mismatch_row = {fieldnames[0]: \"Total Mismatches\"}\n",
    "        for field in fieldnames[1:]:\n",
    "            if field.endswith(\"Result\"):\n",
    "                prefix = field.split()[0].lower()\n",
    "                mismatch_row[field] = mismatch_counter.get(prefix, 0)\n",
    "        writer.writerow(mismatch_row)\n",
    "\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "else:\n",
    "    print(\"No results to save.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
